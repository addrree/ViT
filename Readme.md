# Vision Transformer for Face Identification with Mask Support

Этот проект реализует нейросетевую модель архитектуры **Vision Transformer (ViT)**, 
предназначенную для задачи **идентификации личности по изображению лица**, 
включая обработку **масок, закрывающих части лица** (например, волосы, глаза, рот и т.п.).

##  Описание проекта

В ходе работы:
1. Определяется архитектура ViT для извлечения эмбеддингов изображений лиц.
2. Добавляется механизм **учёта маски** в процессе self-attention (маска может быть в низком разрешении, например 12×12).
3. Производится обучение и тестирование модели на датасете лиц (например, CelebA или кастомный набор).
4. Реализуется возможность **поиска и сопоставления лиц** по эмбеддингам (similarity search).

##  Как использовать

Открыть ноутбук vitlab.ipynb в Jupyter или VS Code.
Запуск ячеек по порядку.
При необходимости указать путь к своим данным (папка с изображениями и масками).
После обучения модель вернёт эмбеддинги лиц и позволит искать похожие изображения.

## Основные компоненты

Vision Transformer (ViT) — базовая архитектура модели.
Mask Attention — механизм учёта видимых областей лица.
ArcFace / CosFace / AM-Softmax — функция потерь для идентификации.
Matplotlib / Seaborn — визуализация эмбеддингов и attention-карт.
PyTorch / timm — обучение и предобученные модели.

##  Метрики и оценка качества

- **Loss** — функция потерь CrossEntropy.
- **Accuracy (Top-1)**
- **Precision**
- **t-SNE / UMAP** — визуализация распределения эмбеддингов для проверки разделимости классов.

## Используемые технологии
Python 3.11+
PyTorch
timm (PyTorch Image Models)
NumPy / Pandas
Matplotlib / Seaborn
scikit-learn
torchvision